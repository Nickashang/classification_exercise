{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification of Bulk Material by Structure Borne Sound\n",
    "\n",
    "Different bulk material creates characteristic structure borne sound when rolling/slipping down a ramp. In this example, the classification of different bulk material from its structure borne sound is shown. As data, audio recordings from different types of screws and bolts rolling down an aluminium ramp are used. A deep neural network (DNN) is trained and evaluated as classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-Processing\n",
    "\n",
    "For the recordings, two microphones where placed below a aluminium ramp in order to pick up the structure borne sound at two different positions. The stereo files contain the audio signals from the two microphones for different materials and repeated measurements.\n",
    "\n",
    "First the segmentation parameters and the filenames are defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_size = 512  # length of segments\n",
    "segment_step = 128  # overlap of segments = segment_size - segment_step\n",
    "\n",
    "n_classes = 5  # number of classes\n",
    "\n",
    "fprefix = 'data/07_12_2017_recordings/'  # directory of recordings\n",
    "\n",
    "# list of filenames and class labels\n",
    "flist = {\n",
    "    'plastic_spheres_1.wav': 0,\n",
    "    'plastic_spheres_2.wav': 0,\n",
    "    'plastic_spheres_3.wav': 0,\n",
    "    'plastic_spheres_4.wav': 0,\n",
    "    'steel_nut_M3_1.wav': 1,\n",
    "    'steel_nut_M3_2.wav': 1,\n",
    "    'steel_nut_M3_3.wav': 1,\n",
    "    'steel_nut_M3_4.wav': 1,\n",
    "    'steel_nut_M4_1.wav': 2,\n",
    "    'steel_nut_M4_2.wav': 2,\n",
    "    'steel_nut_M4_3.wav': 2,\n",
    "    'steel_nut_M4_4.wav': 2,\n",
    "    'messing_nut_M4_1.wav': 3,\n",
    "    'messing_nut_M4_1.wav': 3,\n",
    "    'messing_nut_M4_1.wav': 3,\n",
    "    'messing_nut_M4_1.wav': 3,\n",
    "    'screws_1.wav': 4,\n",
    "    'screws_2.wav': 4,\n",
    "    'screws_3.wav': 4,\n",
    "    'screws_4.wav': 4\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The recordings are now imported, normalized, segmented and composed into the feature matrix $\\mathbf{X}$ and class vector $\\mathbf{y}$. The magnitude spectrum of the samples in a segment is used as feature. \n",
    "\n",
    "\n",
    "First as a function which handles the data pre-processing is defined, followed by the actual composition of the feature matrix and class vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data(fname, nclass, segment_size, segment_step):\n",
    "    # read wav file\n",
    "    data, _ = sf.read(fname)\n",
    "    # normalize level\n",
    "    data = data/np.max(np.abs(data[:]))\n",
    "    # put both channels into one vector\n",
    "    data = np.ndarray.flatten(data, order='F')\n",
    "    # segment and sort into feature matrix\n",
    "    nseg = np.ceil((len(data)-segment_size)/segment_step)\n",
    "    X = np.array([data[i*segment_step:i*segment_step+segment_size]\n",
    "                  for i in range(int(nseg))])\n",
    "    # construct target vector with one hot encoding\n",
    "    y = np.zeros((X.shape[0], n_classes), dtype=np.int)\n",
    "    y[:, nclass] = 1\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "X = np.empty((0, segment_size))\n",
    "y = np.empty((0, n_classes), dtype=np.int)\n",
    "for fname, nclass in flist.items():\n",
    "    Xt, yt = import_data(fprefix+fname, nclass,\n",
    "                         segment_size=segment_size, segment_step=segment_step)\n",
    "    X = np.append(X, Xt, axis=0)\n",
    "    y = np.append(y, yt, axis=0)\n",
    "\n",
    "\n",
    "# use magnitude spectrum as feature\n",
    "X = np.abs(np.fft.rfft(X, axis=1))\n",
    "X = np.float32(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature matrix and class vector is split into a training and a test dataset for training and evaluation of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/4, random_state=42)\n",
    "print('loaded {0:5.0f}/{1:<5.0f} training/test samples'.format(X_train.shape[0], X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construction and Training of Classifier\n",
    "\n",
    "The classifier is constructed as a 2-layer DNN model with two fully connected 64-node layers besides the input and output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(\n",
    "    64, input_dim=X_train.shape[1], activation='relu', kernel_regularizer=keras.regularizers.l2(0.01)))\n",
    "model.add(keras.layers.Dense(64, activation='relu',\n",
    "                             kernel_regularizer=keras.regularizers.l2(0.01)))\n",
    "model.add(keras.layers.Dense(n_classes, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the model is trained using the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs=200, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model accuracy is plotted for visualization of the training progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.title('training loss')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of Classifier\n",
    "\n",
    "The trained classifier is evaluated using the test dataset not used for training of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the classes for the test dataset\n",
    "predictions = model.predict(X_test)\n",
    "predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "# derive the true classes from one-hot encoding\n",
    "true = np.argmax(y_test, axis=1) \n",
    "\n",
    "# print the classification report\n",
    "print(classification_report(true, predictions, target_names=('plastic spheres', 'M3 steel nuts', 'M4 steel nuts', 'M4 messing nuts', 'screws')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "* Analyze the code in detail and understand its function. For instance\n",
    "    * What is the overlap in percent of the data segments extracted from the audio recordings?\n",
    "    * Why can we use a real-valued FFT to represent the segments in the spectral domain?\n",
    "    * Why is it common the split the dataset into a training/test dataset?\n",
    "    * What is an epoch and a batch?\n",
    "    * What insights does the loss give on the training?\n",
    "    * Can you explain the different metrics used in the classification report?\n",
    "    \n",
    "\n",
    "* Change the structure of the deep neural network and check the influence of these changes on the model performance. E.g.\n",
    "    * increase/decrease the depth of single layers\n",
    "    * add/remove layers\n",
    "    * change the activation function\n",
    "\n",
    "\n",
    "* Change the training of the network. E.g.\n",
    "    * change the number of epochs and the batch size\n",
    "    * use a different optimizer\n",
    "\n",
    "\n",
    "* Construct a new model from your insights. What is the best performance you can reach with your model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Exercises\n",
    "\n",
    "* Compute the confusion matrix. What classes are likely to be confused? Why?\n",
    "* Redesign the classifier using a convolutive neural network. What performance can you reach?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Copyright**\n",
    "\n",
    "This notebook is provided as [Open Educational Resource](https://en.wikipedia.org/wiki/Open_educational_resources). Feel free to use the notebook for your own purposes. The text/data is licensed under [Creative Commons Attribution 4.0](https://creativecommons.org/licenses/by/4.0/), the code of the IPython examples under the [MIT license](https://opensource.org/licenses/MIT)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
